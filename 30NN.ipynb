{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import torch\n",
    "import torch.distributions as distributions\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from scipy.io import savemat\n",
    "import scipy.io as sio\n",
    "import sys\n",
    "import importlib\n",
    "import datetime\n",
    "import itertools\n",
    "import pickle\n",
    "import scipy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from numpy import cov\n",
    "from numpy import trace\n",
    "from numpy import iscomplexobj\n",
    "from numpy.random import random\n",
    "from scipy.linalg import sqrtm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/case30\"\n",
    "case_dir = os.path.join(data_dir)\n",
    "number = 20000\n",
    "train_index = 2000\n",
    "valid_index = 16000\n",
    "saveFile = \"data/case30/FC_out/S2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14000, 53])\n",
      "torch.Size([2000, 53])\n",
      "torch.Size([4000, 53])\n"
     ]
    }
   ],
   "source": [
    "#input data\n",
    "mat_input = os.path.join(case_dir, 'inputdata_sample.mat')\n",
    "PQ_injection = np.transpose(scipy.io.loadmat(mat_input)['sampledata'])[0:number,:]\n",
    "P_injection = PQ_injection.real\n",
    "Q_injection = PQ_injection.imag\n",
    "# print(Q_injection.shape)\n",
    "pv = [1-1,2-1,13-1,22-1,23-1,27-1]\n",
    "slack = 1-1\n",
    "P_injection = np.delete(P_injection,slack,1)\n",
    "Q_injection = np.delete(Q_injection,pv,1)\n",
    "# print(Q_injection.shape)\n",
    "PQ_injection = np.concatenate([P_injection, Q_injection], axis=1)      \n",
    "#output data\n",
    "mat_ang = os.path.join(case_dir, 'voltage_ang_reduced.mat')\n",
    "mat_mag = os.path.join(case_dir, 'voltage_mag_reduced.mat')\n",
    "voltage_ang = np.transpose(scipy.io.loadmat(mat_ang)['voltage_ang_reduced'])[0:number,:]\n",
    "voltage_mag = np.transpose(scipy.io.loadmat(mat_mag)['voltage_mag_reduced'])[0:number,:]\n",
    "voltage =  np.concatenate([voltage_ang,voltage_mag], axis=1) \n",
    "yTrain = torch.from_numpy(voltage[0:train_index,:])\n",
    "xTrain = torch.from_numpy(PQ_injection[0:train_index,:])\n",
    "yValid = torch.from_numpy(voltage[train_index:valid_index,:])\n",
    "xValid = torch.from_numpy(PQ_injection[train_index:valid_index,:])\n",
    "yTest = torch.from_numpy(voltage[valid_index:number,:])\n",
    "xTest = torch.from_numpy(PQ_injection[valid_index:number,:])\n",
    "dataset = torch.utils.data.TensorDataset(xTrain, yTrain)\n",
    "print(xValid.shape)\n",
    "print(xTrain.shape)\n",
    "print(xTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, hidden_dim=100, img_size=53, labels_dim=53, lr=5e-05, n_cpu=8, n_epochs=0)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=1000, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=32, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.00005, help=\"learning rate\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--labels_dim\", type=int, default=53, help=\"dimensionality of the latent space\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=53, help=\"size of each image dimension\")\n",
    "parser.add_argument(\"--hidden_dim\", type=int, default=100, help=\"size of hidden_dim\")\n",
    "opt = parser.parse_args(args=[])\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "# Initialize generator and discriminator\n",
    "time = []\n",
    "loss_train = []  \n",
    "loss_valid = [] \n",
    "batch_loss_train = [] \n",
    "avg_train_losses = []\n",
    "class FC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FC, self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(opt.labels_dim, opt.hidden_dim),\n",
    "            *block(opt.hidden_dim, opt.hidden_dim),\n",
    "            #*block(opt.hidden_dim, opt.hidden_dim),\n",
    "            nn.Linear(opt.hidden_dim, opt.img_size),\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        out = self.model(z)\n",
    "        return out\n",
    "# Initialize generator and discriminator\n",
    "MLP = FC()\n",
    "L2_loss = nn.MSELoss()\n",
    "if cuda:\n",
    "    MLP.cuda()\n",
    "    L2_loss.cuda()\n",
    "# Configure data loader\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Optimizers\n",
    "optimizer = torch.optim.Adam(MLP.parameters(), lr=opt.lr)\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "batches_done = 0\n",
    "for epoch in range(opt.n_epochs):\n",
    "\n",
    "    for i, (xTrain, yTrain) in enumerate(dataloader):\n",
    "            # -----------------\n",
    "            #  Train Generator\n",
    "            # -----------------\n",
    "            # Start measuring time\n",
    "            startTime = datetime.datetime.now()\n",
    "            \n",
    "            # Reset gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Generate a batch of samples\n",
    "            yHatTrain = MLP(xTrain.float())\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = L2_loss(yHatTrain,yTrain.float())\n",
    "            \n",
    "            # Compute gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # Optimize\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Finish measuring time\n",
    "            endTime = datetime.datetime.now()\n",
    "            \n",
    "            timeElapsed = abs(endTime - startTime).total_seconds()\n",
    "            \n",
    "            time.append(timeElapsed)\n",
    "            \n",
    "            batch_loss_train.append(loss.item())  \n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d][G loss: %.8f]\"\n",
    "                % (epoch, opt.n_epochs, batches_done % len(dataloader), len(dataloader), loss.item()))\n",
    "            #VALIDATION\n",
    "            if (batches_done % (len(yValid)//opt.batch_size) == 0):\n",
    "\n",
    "                with torch.no_grad(): \n",
    "                    yHatValid = MLP(xValid.float()) \n",
    "                    # Compute loss\n",
    "                    lossValueValid = L2_loss(yHatValid, yValid)\n",
    "                    loss_valid.append(lossValueValid.item())\n",
    "                    \n",
    "                if epoch >= 599:\n",
    "                    if (epoch == 599):\n",
    "                        bestScore = lossValueValid\n",
    "                        torch.save(MLP.state_dict(), saveFile +'Best'+'.ckpt')\n",
    "                        torch.save(optimizer.state_dict(), saveFile+'Optim'+'Best'+'.ckpt')\n",
    "                    else:\n",
    "                        thisValidScore = lossValueValid\n",
    "                        if thisValidScore < bestScore:\n",
    "                            bestScore = thisValidScore\n",
    "                            torch.save(MLP.state_dict(), saveFile + 'Best'+'.ckpt')\n",
    "                            torch.save(optimizer.state_dict(), saveFile+'Optim'+'Best'+'.ckpt') \n",
    "            batches_done += 1\n",
    "    train_loss = np.average(batch_loss_train)\n",
    "    avg_train_losses.append(train_loss)\n",
    "    batch_loss_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(time, saveFile + 'Time')\n",
    "torch.save(MLP.state_dict(), saveFile + 'Last'+'.ckpt')\n",
    "torch.save(optimizer.state_dict(), saveFile+'Optim'+'Last'+'.ckpt') \n",
    "np.save(saveFile+'Train',avg_train_losses)\n",
    "np.save(saveFile+'Valid',loss_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(avg_train_losses[200:800])\n",
    "plt.ylabel('mean squared loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('neurons = 200')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_valid[300:1000:4])\n",
    "plt.ylabel('mean squared loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP.eval()\n",
    "yHatTest = MLP(xTest.float())\n",
    "rmse_test = np.mean((yHatTest.detach().numpy()-yTest.detach().numpy())**2)\n",
    "print(rmse_test)\n",
    "rmse_test1 = np.sqrt(np.mean((yHatTest.detach().numpy()-yTest.detach().numpy())**2,0))\n",
    "print(rmse_test1)\n",
    "print(np.mean(rmse_test1[0:29]))\n",
    "print(np.mean(rmse_test1[29:53]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(saveFile+'rmse_test_last',rmse_test1)\n",
    "np.save(saveFile+'yHatTest_last',yHatTest.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FC()\n",
    "model.load_state_dict(torch.load(saveFile + 'Best'+'.ckpt'))\n",
    "optimizer.load_state_dict(torch.load(saveFile+'Optim'+'Best'+'.ckpt'))\n",
    "model.eval()\n",
    "yHatTest = model(xTest.float())\n",
    "rmse_test2 = np.mean((yHatTest.detach().numpy()-yTest.detach().numpy())**2)\n",
    "print(rmse_test2)\n",
    "rmse_test3 = np.sqrt(np.mean((yHatTest.detach().numpy()-yTest.detach().numpy())**2,0))\n",
    "print(rmse_test3)\n",
    "print(np.mean(rmse_test3[0:29]))\n",
    "print(np.mean(rmse_test3[29:53]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(saveFile+'rmse_test_best',rmse_test3)\n",
    "np.save(saveFile+'yHatTest_best',yHatTest.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
