{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 8409,
     "status": "ok",
     "timestamp": 1620813953819,
     "user": {
      "displayName": "Kejun Chen",
      "photoUrl": "",
      "userId": "04215457871698777237"
     },
     "user_tz": 420
    },
    "id": "pDKFB6E0MmGq"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import torch\n",
    "import torch.distributions as distributions\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from scipy.io import savemat\n",
    "import scipy.io as sio\n",
    "import sys\n",
    "import importlib\n",
    "import datetime\n",
    "import itertools\n",
    "import pickle\n",
    "import scipy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import cov\n",
    "from numpy import trace\n",
    "from numpy import iscomplexobj\n",
    "from numpy.random import random\n",
    "from scipy.linalg import sqrtm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1620813956422,
     "user": {
      "displayName": "Kejun Chen",
      "photoUrl": "",
      "userId": "04215457871698777237"
     },
     "user_tz": 420
    },
    "id": "LNKPu69nMmGz"
   },
   "outputs": [],
   "source": [
    "data_dir = \"data/case30\"\n",
    "case_dir = os.path.join(data_dir)\n",
    "number = 20000\n",
    "train_index = 12000\n",
    "valid_index = 16000\n",
    "saveFile = \"data/case30/AD_TPBNN/S10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5126,
     "status": "ok",
     "timestamp": 1620813963892,
     "user": {
      "displayName": "Kejun Chen",
      "photoUrl": "",
      "userId": "04215457871698777237"
     },
     "user_tz": 420
    },
    "id": "B8CLW1NZMmG0",
    "outputId": "e7425cab-a43c-4ae5-b07a-276193010434"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 30])\n",
      "torch.Size([4000, 60])\n",
      "torch.Size([12000, 60])\n",
      "torch.Size([12000, 60])\n",
      "torch.Size([4000, 60])\n",
      "torch.Size([12000, 60])\n"
     ]
    }
   ],
   "source": [
    "#input data\n",
    "mat_input = os.path.join(case_dir, 'outputdata_sample.mat')\n",
    "PQ_injection = np.transpose(scipy.io.loadmat(mat_input)['power_injection'])[0:number,:]\n",
    "P_injection = PQ_injection.real\n",
    "Q_injection = PQ_injection.imag\n",
    "\n",
    "PQ_injection_d = np.concatenate([P_injection, Q_injection], axis=1)  \n",
    "\n",
    "# print(Q_injection.shape)\n",
    "pv = [1-1,2-1,13-1,22-1,23-1,27-1]\n",
    "slack = 1-1\n",
    "P_injection = np.delete(P_injection,slack,1)\n",
    "Q_injection = np.delete(Q_injection,pv,1)\n",
    "# print(Q_injection.shape)\n",
    "PQ_injection = np.concatenate([P_injection, Q_injection], axis=1)   \n",
    "\n",
    "# knwon voltage \n",
    "mat_input = os.path.join(case_dir, 'voltage_known.mat')\n",
    "voltage_known = np.transpose(scipy.io.loadmat(mat_input)['voltage_known'])[0:number,:]\n",
    "PQ_injection_voltage_known  = np.concatenate([PQ_injection, voltage_known], axis=1)   \n",
    "\n",
    "#topo_info\n",
    "mat_input = os.path.join(case_dir, 'topo_info.mat')\n",
    "topo_info = torch.from_numpy(np.transpose(scipy.io.loadmat(mat_input)['topo_info']))\n",
    "print(topo_info.shape)\n",
    "#output data\n",
    "mat_ang = os.path.join(case_dir, 'voltage_real.mat')\n",
    "mat_mag = os.path.join(case_dir, 'voltage_imag.mat')\n",
    "voltage_real = np.transpose(scipy.io.loadmat(mat_ang)['voltage_real'])[0:number,:]\n",
    "voltage_imag = np.transpose(scipy.io.loadmat(mat_mag)['voltage_imag'])[0:number,:]\n",
    "\n",
    "voltage =  np.concatenate([voltage_real,voltage_imag], axis=1) \n",
    "\n",
    "xTrain = torch.from_numpy(PQ_injection_voltage_known[0:train_index,:])\n",
    "yTrain = torch.from_numpy(voltage[0:train_index,:])\n",
    "yTrain_d = torch.from_numpy(PQ_injection_d[0:train_index,:])\n",
    "\n",
    "xValid = torch.from_numpy(PQ_injection_voltage_known[train_index:valid_index,:])\n",
    "yValid = torch.from_numpy(voltage[train_index:valid_index,:])\n",
    "yValid_d = torch.from_numpy(PQ_injection_d[train_index:valid_index,:])\n",
    "\n",
    "xTest = torch.from_numpy(PQ_injection_voltage_known[valid_index:number,:])\n",
    "yTest = torch.from_numpy(voltage[valid_index:number,:])\n",
    "yTest_d = torch.from_numpy(PQ_injection_d[valid_index:number,:])\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(xTrain, yTrain, yTrain_d)\n",
    "print(xValid.shape)\n",
    "print(xTrain.shape)\n",
    "print(yTrain.shape)\n",
    "print(xTest.shape)\n",
    "print(yTrain_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 591,
     "status": "ok",
     "timestamp": 1620813964502,
     "user": {
      "displayName": "Kejun Chen",
      "photoUrl": "",
      "userId": "04215457871698777237"
     },
     "user_tz": 420
    },
    "id": "pMTN8JoRMmG1",
    "outputId": "378635c9-279f-4abf-9d5d-f6b5565f66a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(alpha=50, batch_size=32, hidden_dim=100, img_size=60, labels_dim=60, lr=0.001, n_cpu=8, n_epochs=600)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=600, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=32, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.001, help=\"learning rate\")\n",
    "parser.add_argument(\"--alpha\", type=float, default=50, help=\"super:unsuper\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--labels_dim\", type=int, default=60, help=\"dimensionality of the latent space\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=60, help=\"size of each image dimension\")\n",
    "parser.add_argument(\"--hidden_dim\", type=int, default=100, help=\"size of hidden_dim\")\n",
    "opt = parser.parse_args(args=[])\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 578,
     "status": "ok",
     "timestamp": 1620813964503,
     "user": {
      "displayName": "Kejun Chen",
      "photoUrl": "",
      "userId": "04215457871698777237"
     },
     "user_tz": 420
    },
    "id": "wYU48N7_T0ec",
    "outputId": "9b152e93-61a2-4721-ae29-e1f1edd62c2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "print(cuda)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 6508,
     "status": "ok",
     "timestamp": 1620813994788,
     "user": {
      "displayName": "Kejun Chen",
      "photoUrl": "",
      "userId": "04215457871698777237"
     },
     "user_tz": 420
    },
    "id": "ELzb-Fn-MmG1"
   },
   "outputs": [],
   "source": [
    "# Initialize generator and discriminator\n",
    "time = []\n",
    "loss_valid = [] \n",
    "batch_loss_train = [] \n",
    "avg_train_losses = []\n",
    "batch_loss_en_train = [] \n",
    "avg_train_losses_en = []\n",
    "\n",
    "class Multiply(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Multiply, self).__init__()\n",
    "\n",
    "        WG_topo1 = torch.randn(30,30) \n",
    "        WB_topo1 = torch.randn(30,30) \n",
    "\n",
    "        nn.init.kaiming_uniform_(WG_topo1)\n",
    "        nn.init.kaiming_uniform_(WB_topo1)\n",
    "\n",
    "        WG_topo = WG_topo1 * topo_info\n",
    "        WB_topo = WB_topo1 * topo_info\n",
    "\n",
    "        self.WG = torch.nn.Parameter(WG_topo) \n",
    "        self.WB = torch.nn.Parameter(WB_topo)\n",
    "\n",
    "        self.ones = torch.ones(30,1)\n",
    "\n",
    "        self.bp_for_optimizer = torch.nn.Parameter(torch.randn(30,))\n",
    "        self.bq_for_optimizer = torch.nn.Parameter(torch.randn(30,))\n",
    "        \n",
    "        #nn.init.kaiming_uniform_(self.WG)\n",
    "        #nn.init.kaiming_uniform_(self.WB)\n",
    "        nn.init.uniform_(self.bp_for_optimizer)\n",
    "        nn.init.uniform_(self.bq_for_optimizer)\n",
    "\n",
    "    def bilinear(self,out_en):\n",
    "                  \n",
    "        bnn1 = torch.bmm(out_en[:,0:30].unsqueeze(2), out_en[:,0:30].unsqueeze(1)) \n",
    "        bnn2 = torch.bmm(out_en[:,30:60].unsqueeze(2), out_en[:,30:60].unsqueeze(1)) \n",
    "        bnn3 = torch.bmm(out_en[:,0:30].unsqueeze(2), out_en[:,30:60].unsqueeze(1)) \n",
    "        bnn4 = torch.bmm(out_en[:,30:60].unsqueeze(2), out_en[:,0:30].unsqueeze(1)) \n",
    "        \n",
    "        return bnn1,bnn2,bnn3,bnn4\n",
    "        \n",
    "    def forward(self,out_en):\n",
    "        \n",
    "        [bnn1,bnn2,bnn3,bnn4] = self.bilinear(out_en)\n",
    "\n",
    "        bias_bp = self.bp_for_optimizer.repeat(32, 1)\n",
    "        bias_bq = self.bq_for_optimizer.repeat(32, 1)\n",
    "\n",
    "        S1 = (bnn1+bnn2) * self.WG + (bnn4-bnn3) * self.WB\n",
    "        S2 = (bnn4-bnn3) * self.WG  - (bnn1+bnn2) * self.WB\n",
    "\n",
    "        out_d1 = torch.squeeze(torch.matmul(S1, self.ones.to(device))) + bias_bp\n",
    "        out_d2 = torch.squeeze(torch.matmul(S2, self.ones.to(device))) + bias_bq\n",
    "        return out_d1, out_d2\n",
    "    \n",
    "    def evaltest(self, out_en):\n",
    "        \n",
    "        [bnn1,bnn2,bnn3,bnn4] = self.bilinear(out_en)\n",
    "        \n",
    "        bias_bp_test = self.bp_for_optimizer.repeat(4000, 1)\n",
    "        bias_bq_test = self.bq_for_optimizer.repeat(4000, 1)\n",
    "        \n",
    "        S1_test = (bnn1+bnn2) * self.WG + (bnn4-bnn3) * self.WB\n",
    "        S2_test = (bnn4-bnn3) * self.WG  - (bnn1+bnn2) * self.WB\n",
    "\n",
    "        out_d1_test = torch.squeeze(torch.matmul(S1_test, self.ones.to(device))) + bias_bp_test\n",
    "        out_d2_test = torch.squeeze(torch.matmul(S2_test, self.ones.to(device))) + bias_bq_test\n",
    "        \n",
    "        return out_d1_test, out_d2_test\n",
    "    \n",
    "class FC(nn.Module):\n",
    "    def __init__(self, Multiply):\n",
    "        super(FC, self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            return layers\n",
    "        \n",
    "        self.model_en = nn.Sequential(\n",
    "            *block(opt.labels_dim, opt.hidden_dim),\n",
    "            *block(opt.hidden_dim, opt.hidden_dim),\n",
    "            nn.Linear(opt.hidden_dim, opt.img_size),\n",
    "        )\n",
    "        \n",
    "        self.model_d = Multiply()\n",
    "\n",
    "        \n",
    "    def forward(self, z):\n",
    "        out_en = self.model_en(z)\n",
    "\n",
    "        [out_d1, out_d2] = self.model_d(out_en)\n",
    "        \n",
    "        out = torch.cat((out_d1, out_d2),1)\n",
    "\n",
    "        return out_en, out\n",
    "    \n",
    "    def evaltest(self, z):\n",
    "        out_en_test = self.model_en(z)\n",
    "\n",
    "        [out_d1_test, out_d2_test] = self.model_d.evaltest(out_en_test)\n",
    "        \n",
    "        out_test = torch.cat((out_d1_test, out_d2_test),1)\n",
    "\n",
    "        return out_en_test, out_test\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "MLP = FC(Multiply)\n",
    "L2_loss = nn.MSELoss()\n",
    "if cuda:\n",
    "    MLP.cuda()\n",
    "    L2_loss.cuda()\n",
    "# Configure data loader\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory = True,\n",
    ")\n",
    "\n",
    "# Optimizers\n",
    "optimizer = torch.optim.Adam(MLP.parameters(), lr=opt.lr)\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "batches_done = 0\n",
    "for epoch in range(opt.n_epochs):\n",
    "\n",
    "    for i, (xTrain, yTrain, yTrain_d) in enumerate(dataloader):\n",
    "            # -----------------\n",
    "            #  Train Generator\n",
    "            # -----------------\n",
    "            # Start measuring time\n",
    "            startTime = datetime.datetime.now()\n",
    "            \n",
    "            # Reset gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Generate a batch of samples\n",
    "            [yHatTrain_en,yHatTrain_d] = MLP(xTrain.float().to(device)) \n",
    "            \n",
    "            # Compute loss\n",
    "            loss = opt.alpha * L2_loss(yHatTrain_en,yTrain.float().to(device)) + L2_loss(yHatTrain_d,yTrain_d.float().to(device))\n",
    "\n",
    "            loss_en = L2_loss(yHatTrain_en,yTrain.float().to(device))\n",
    "            # Compute gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # Optimize\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Finish measuring time\n",
    "            endTime = datetime.datetime.now()\n",
    "            \n",
    "            timeElapsed = abs(endTime - startTime).total_seconds()\n",
    "            \n",
    "            time.append(timeElapsed)\n",
    "            \n",
    "            batch_loss_train.append(loss.item())  \n",
    "            batch_loss_en_train.append(loss_en.item()) \n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d][G loss: %.8f]\"\n",
    "                % (epoch, opt.n_epochs, batches_done % len(dataloader), len(dataloader), loss.item()))\n",
    "            #VALIDATION\n",
    "            if (batches_done % (len(yValid)//opt.batch_size) == 0):\n",
    "\n",
    "                with torch.no_grad(): \n",
    "                    [yHatValid_en,yHatValid_d] = MLP.evaltest(xValid.float().to(device)) \n",
    "                    # Compute loss\n",
    "                    lossValueValid = L2_loss(yHatValid_en, yValid.to(device))\n",
    "                    loss_valid.append(lossValueValid.item())\n",
    "                    \n",
    "                if epoch >= 299:\n",
    "                    if (epoch == 299):\n",
    "                        bestScore = lossValueValid\n",
    "                        torch.save(MLP.state_dict(), saveFile +'Best'+'.ckpt')\n",
    "                        torch.save(optimizer.state_dict(), saveFile+'Optim'+'Best'+'.ckpt')\n",
    "                    else:\n",
    "                        thisValidScore = lossValueValid\n",
    "                        if thisValidScore < bestScore:\n",
    "                            bestScore = thisValidScore\n",
    "                            torch.save(MLP.state_dict(), saveFile + 'Best'+'.ckpt')\n",
    "                            torch.save(optimizer.state_dict(), saveFile+'Optim'+'Best'+'.ckpt') \n",
    "            batches_done += 1\n",
    "    train_loss = np.average(batch_loss_train)\n",
    "    avg_train_losses.append(train_loss)\n",
    "    train_loss_en = np.average(batch_loss_en_train)\n",
    "    avg_train_losses_en.append(train_loss_en)\n",
    "    batch_loss_train = []\n",
    "    batch_loss_en_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1620815386161,
     "user": {
      "displayName": "Kejun Chen",
      "photoUrl": "",
      "userId": "04215457871698777237"
     },
     "user_tz": 420
    },
    "id": "ch2Cm2mVMmIb"
   },
   "outputs": [],
   "source": [
    "torch.save(time, saveFile + 'Time')\n",
    "torch.save(MLP.state_dict(), saveFile + 'Last'+'.ckpt')\n",
    "torch.save(optimizer.state_dict(), saveFile+'Optim'+'Last'+'.ckpt') \n",
    "np.save(saveFile+'Train',avg_train_losses)\n",
    "np.save(saveFile+'Valid',loss_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(avg_train_losses_en[100:2000])\n",
    "plt.ylabel('mean squared loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('neurons = 200')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_valid[100:9000:4])\n",
    "plt.ylabel('mean squared loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP.eval()\n",
    "[yHatTest_en, yHatTest_d] = MLP.evaltest(xTest.float().to(device))\n",
    "rmse_test = np.mean((yHatTest_en.detach().cpu().numpy()-yTest.detach().numpy())**2)\n",
    "print(rmse_test)\n",
    "rmse_test_d = np.mean((yHatTest_d.detach().cpu().numpy()-yTest_d.detach().numpy())**2)\n",
    "print(rmse_test_d)\n",
    "rmse_test1 = np.sqrt(np.mean((yHatTest_en.detach().cpu().numpy()-yTest.detach().numpy())**2,0))\n",
    "print(rmse_test1)\n",
    "print(np.mean(rmse_test1[0:29]))\n",
    "print(np.mean(rmse_test1[29:53]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1620815397985,
     "user": {
      "displayName": "Kejun Chen",
      "photoUrl": "",
      "userId": "04215457871698777237"
     },
     "user_tz": 420
    },
    "id": "mNVN-H1iMmId"
   },
   "outputs": [],
   "source": [
    "np.save(saveFile+'rmse_test_last',rmse_test1)\n",
    "np.save(saveFile+'yHatTest_last',yHatTest_en.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FC(Multiply)\n",
    "model.load_state_dict(torch.load(saveFile + 'Best'+'.ckpt'))\n",
    "optimizer.load_state_dict(torch.load(saveFile+'Optim'+'Best'+'.ckpt'))\n",
    "model.eval()\n",
    "[yHatTest_en, yHatTest_d] = model.evaltest(xTest.float().to(device))\n",
    "rmse_test = np.mean((yHatTest_en.detach().cpu().numpy()-yTest.detach().numpy())**2)\n",
    "print(rmse_test)\n",
    "rmse_test_d = np.mean((yHatTest_d.detach().cpu().numpy()-yTest_d.detach().numpy())**2)\n",
    "print(rmse_test_d)\n",
    "rmse_test3 = np.sqrt(np.mean((yHatTest_en.detach().cpu().numpy()-yTest.detach().numpy())**2,0))\n",
    "print(rmse_test3)\n",
    "print(np.mean(rmse_test3[0:29]))\n",
    "print(np.mean(rmse_test3[29:53]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 290,
     "status": "ok",
     "timestamp": 1620815402495,
     "user": {
      "displayName": "Kejun Chen",
      "photoUrl": "",
      "userId": "04215457871698777237"
     },
     "user_tz": 420
    },
    "id": "zQXPnlhnMmIe"
   },
   "outputs": [],
   "source": [
    "np.save(saveFile+'rmse_test_best',rmse_test3)\n",
    "np.save(saveFile+'yHatTest_best',yHatTest_en.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xVDrECe1MmIe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymfPQ4uFMmIe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EP3fDh7dMmIf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "30NN_AD_TPBNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
