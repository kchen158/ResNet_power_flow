{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import torch\n",
    "import torch.distributions as distributions\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from scipy.io import savemat\n",
    "import scipy.io as sio\n",
    "import sys\n",
    "import importlib\n",
    "import datetime\n",
    "import itertools\n",
    "import pickle\n",
    "import scipy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import cov\n",
    "from numpy import trace\n",
    "from numpy import iscomplexobj\n",
    "from numpy.random import random\n",
    "from scipy.linalg import sqrtm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/case30\"\n",
    "case_dir = os.path.join(data_dir)\n",
    "number = 20000\n",
    "train_index = 12000\n",
    "valid_index = 16000\n",
    "saveFile = \"data/case30/J_delta/S3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 53)\n",
      "torch.Size([4000, 53])\n",
      "torch.Size([12000, 53])\n",
      "torch.Size([4000, 53])\n",
      "tensor([[-7.2105e-04, -4.2188e-02, -5.0055e-02,  ...,  9.5658e-01,\n",
      "          9.2214e-01,  9.1293e-01],\n",
      "        [-4.9751e-02, -8.2887e-02, -9.9444e-02,  ...,  9.5778e-01,\n",
      "          9.1082e-01,  9.0449e-01],\n",
      "        [ 1.6693e-02, -7.9544e-03, -8.2544e-03,  ...,  9.7276e-01,\n",
      "          9.2232e-01,  9.0347e-01],\n",
      "        ...,\n",
      "        [-6.7133e-04, -1.9850e-02, -2.2742e-02,  ...,  9.6873e-01,\n",
      "          9.4074e-01,  9.1911e-01],\n",
      "        [-2.5308e-02, -5.3508e-02, -6.3837e-02,  ...,  9.5578e-01,\n",
      "          9.2168e-01,  8.9642e-01],\n",
      "        [-2.6976e-03, -4.0584e-02, -4.7813e-02,  ...,  9.5785e-01,\n",
      "          9.3147e-01,  9.1113e-01]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#input data\n",
    "mat_input = os.path.join(case_dir, 'inputdata_sample.mat')\n",
    "PQ_injection = np.transpose(scipy.io.loadmat(mat_input)['sampledata'])[0:number,:]\n",
    "P_injection = PQ_injection.real\n",
    "Q_injection = PQ_injection.imag\n",
    "sensitivity = os.path.join(case_dir, 'W_delta.mat')\n",
    "S_original = scipy.io.loadmat(sensitivity)['weights']\n",
    "S = copy.deepcopy(S_original)\n",
    "bias = os.path.join(case_dir, 'bias_delta.mat')\n",
    "bias_original = scipy.io.loadmat(bias)['bias']\n",
    "bias = copy.deepcopy(bias_original)\n",
    "pv = [1-1,2-1,13-1,22-1,23-1,27-1]\n",
    "slack = 1-1\n",
    "P_injection = np.delete(P_injection,slack,1)\n",
    "Q_injection = np.delete(Q_injection,pv,1)\n",
    "# print(Q_injection.shape)\n",
    "PQ_injection = np.concatenate([P_injection, Q_injection], axis=1)   \n",
    "print(PQ_injection.shape)\n",
    "#output data\n",
    "mat_ang = os.path.join(case_dir, 'voltage_ang_reduced.mat')\n",
    "mat_mag = os.path.join(case_dir, 'voltage_mag_reduced.mat')\n",
    "voltage_ang = np.transpose(scipy.io.loadmat(mat_ang)['voltage_ang_reduced'])[0:number,:]\n",
    "voltage_mag = np.transpose(scipy.io.loadmat(mat_mag)['voltage_mag_reduced'])[0:number,:]\n",
    "voltage =  np.concatenate([voltage_ang,voltage_mag], axis=1) \n",
    "yTrain = torch.from_numpy(voltage[0:train_index,:])\n",
    "xTrain = torch.from_numpy(PQ_injection[0:train_index,:])\n",
    "yValid = torch.from_numpy(voltage[train_index:valid_index,:])\n",
    "xValid = torch.from_numpy(PQ_injection[train_index:valid_index,:])\n",
    "yTest = torch.from_numpy(voltage[valid_index:number,:])\n",
    "xTest = torch.from_numpy(PQ_injection[valid_index:number,:])\n",
    "dataset = torch.utils.data.TensorDataset(xTrain, yTrain)\n",
    "print(xValid.shape)\n",
    "print(xTrain.shape)\n",
    "print(xTest.shape)\n",
    "print(yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, hidden1_dim=100, img_size=53, labels_dim=53, lr=0.0001, n_cpu=8, n_epochs=50, output1_dim=100)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=50, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=32, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.0001, help=\"learning rate\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--labels_dim\", type=int, default=53, help=\"dimensionality of the latent space\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=53, help=\"size of each image dimension\")\n",
    "parser.add_argument(\"--hidden1_dim\", type=int, default=100, help=\"size of hidden_dim\")\n",
    "parser.add_argument(\"--output1_dim\", type=int, default=100, help=\"size of hidden_dim\")\n",
    "opt = parser.parse_args(args=[])\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_feat, hidden_feat, out_feat):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.layers = nn.Linear(opt.labels_dim, opt.img_size)\n",
    "        self.layers1 = nn.Linear(opt.labels_dim, hidden_feat)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layers2 = nn.Linear(hidden_feat, hidden_feat)\n",
    "        self.layers3 = nn.Linear(hidden_feat, out_feat)\n",
    "        self.layers.weight = torch.nn.Parameter(Tensor(S))\n",
    "        self.layers.bias = torch.nn.Parameter(torch.squeeze(Tensor(bias),1))\n",
    "    def forward(self, x):\n",
    "        identity = self.layers(x)\n",
    "\n",
    "        out = self.layers1(x)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.layers2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.layers3(out)\n",
    "        out = identity + out\n",
    "        #out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(self, block):\n",
    "        super(Resnet, self).__init__()\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        self.block = block\n",
    "        self.model = nn.Sequential(\n",
    "            block(opt.labels_dim,opt.hidden1_dim, opt.img_size),\n",
    "            #block(opt.output1_dim,opt.hidden2_dim,opt.output2_dim),\n",
    "            #block(opt.output1_dim,opt.hidden2_dim,opt.output2_dim),\n",
    "            #nn.Linear(opt.output1_dim,opt.img_size),\n",
    "        )   \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "MLP = Resnet(BasicBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generator and discriminator\n",
    "time = []\n",
    "loss_train = []  \n",
    "loss_valid = [] \n",
    "batch_loss_train = [] \n",
    "avg_train_losses = []\n",
    "L2_loss = nn.MSELoss()\n",
    "if cuda:\n",
    "    MLP.cuda()\n",
    "    L2_loss.cuda()\n",
    "# Configure data loader\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Optimizers\n",
    "optimizer = torch.optim.Adam(MLP.parameters(), lr=opt.lr)\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "# Create batch of latent vectors that we will use to check the progression of the generator\n",
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "\n",
    "batches_done = 0\n",
    "\n",
    "for epoch in range(opt.n_epochs):\n",
    "\n",
    "    for i, (xTrain, yTrain) in enumerate(dataloader):\n",
    "        # Configure input\n",
    "            # -----------------\n",
    "            #  Train Generator\n",
    "            # -----------------\n",
    "            startTime = datetime.datetime.now()\n",
    "            optimizer.zero_grad()\n",
    "            # Generate a batch of images\n",
    "            yHatTrain = MLP(xTrain.float())\n",
    "            # Adversarial loss\n",
    "            loss = L2_loss(yHatTrain,yTrain.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            endTime = datetime.datetime.now()\n",
    "            timeElapsed = abs(endTime - startTime).total_seconds()\n",
    "            time.append(timeElapsed)\n",
    "            batch_loss_train.append(loss.item()) \n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d][G loss: %.8f]\"\n",
    "                % (epoch, opt.n_epochs, batches_done % len(dataloader), len(dataloader), loss.item())\n",
    "            )       \n",
    "            if (batches_done % (len(yValid)//opt.batch_size) == 0):\n",
    "                with torch.no_grad(): \n",
    "                    yHatValid = MLP(xValid.float()) \n",
    "                    # Compute loss\n",
    "                    lossValueValid = L2_loss(yHatValid, yValid)\n",
    "                    loss_valid.append(lossValueValid.item())\n",
    "                if epoch >= 799:\n",
    "                    if (epoch == 799):\n",
    "                        bestScore = lossValueValid\n",
    "                        torch.save(MLP.state_dict(), saveFile +'Best'+'.ckpt')\n",
    "                        torch.save(optimizer.state_dict(), saveFile+'Optim'+'Best'+'.ckpt')\n",
    "                    else:\n",
    "                        thisValidScore = lossValueValid\n",
    "                        if thisValidScore < bestScore:\n",
    "                            bestScore = thisValidScore\n",
    "                            torch.save(MLP.state_dict(), saveFile + 'Best'+'.ckpt')\n",
    "                            torch.save(optimizer.state_dict(), saveFile+'Optim'+'Best'+'.ckpt')                  \n",
    "            batches_done += 1\n",
    "    train_loss = np.average(batch_loss_train)\n",
    "    avg_train_losses.append(train_loss)\n",
    "    batch_loss_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(time, saveFile + 'Time')\n",
    "torch.save(MLP.state_dict(), saveFile + 'Last'+'.ckpt')\n",
    "torch.save(optimizer.state_dict(), saveFile+'Optim'+'Last'+'.ckpt') \n",
    "np.save(saveFile+'Train',avg_train_losses)\n",
    "np.save(saveFile+'Valid',loss_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(avg_train_losses[200:2000])\n",
    "plt.ylabel('mean squared loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('neurons = 200')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_valid[500:6000:4])\n",
    "plt.ylabel('mean squared loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number = 200\n",
    "MLP.eval()\n",
    "yHatTest = MLP(xTest.float())\n",
    "rmse_test = np.mean((yHatTest.detach().numpy()-yTest.detach().numpy())**2)\n",
    "print(rmse_test)\n",
    "rmse_test1 = np.sqrt(np.mean((yHatTest.detach().numpy()-yTest.detach().numpy())**2,0))\n",
    "print(rmse_test1)\n",
    "print(np.mean(rmse_test1[0:29]))\n",
    "print(np.mean(rmse_test1[29:53]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(saveFile+'rmse_test_last',rmse_test1)\n",
    "np.save(saveFile+'yHatTest_last',yHatTest.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet(BasicBlock)\n",
    "model.load_state_dict(torch.load(saveFile + 'Best'+'.ckpt'))\n",
    "optimizer.load_state_dict(torch.load(saveFile+'Optim'+'Best'+'.ckpt'))\n",
    "model.eval()\n",
    "yHatTest = model(xTest.float())\n",
    "rmse_test2 = np.mean((yHatTest.detach().numpy()-yTest.detach().numpy())**2)\n",
    "print(rmse_test2)\n",
    "rmse_test3 = np.sqrt(np.mean((yHatTest.detach().numpy()-yTest.detach().numpy())**2,0))\n",
    "print(rmse_test3)\n",
    "print(np.mean(rmse_test3[0:29]))\n",
    "print(np.mean(rmse_test3[29:53]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(saveFile+'rmse_test_best',rmse_test3)\n",
    "np.save(saveFile+'yHatTest_best',yHatTest.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
